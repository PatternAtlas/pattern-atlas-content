<?xml version="1.1" encoding="UTF-8" standalone="no"?>
<databaseChangeLog xmlns="http://www.liquibase.org/xml/ns/dbchangelog" xmlns:ext="http://www.liquibase.org/xml/ns/dbchangelog-ext" xmlns:pro="http://www.liquibase.org/xml/ns/pro" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.liquibase.org/xml/ns/dbchangelog-ext http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-ext.xsd http://www.liquibase.org/xml/ns/pro http://www.liquibase.org/xml/ns/pro/liquibase-pro-latest.xsd http://www.liquibase.org/xml/ns/dbchangelog http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-latest.xsd">
    <changeSet author="Felix Truger" id="1710330017868-3">
        <insert tableName="pattern">
            <column name="id" value="d3f6b18a-c8c1-4010-b750-b71d95eb5f5e"/>
            <column name="name" value="Biased Initial State"/>
            <column name="uri" value="https://patternpedia.org/patternLanguages/quantumAlgorithmPatterns/biasedInitialState"/>
            <column name="content" value="{&quot;Alias&quot;: &quot;&#8212;&quot;, &quot;Forces&quot;: &quot;Moreover, current quantum devices are error-prone, thus, the depth of executable quantum circuits is limited. However, including approximations requires special care, as it can limit the quantum algorithm in an unintended way [[Cain et al. 2022]](https://arxiv.org/abs/2207.05089)[[Truger et al. 2024]](https://arxiv.org/abs/2402.17378). Also, changing the initial state may require additional adaptations of corresponding parts of the quantum circuit [[Egger et al. 2021]](https://doi.org/10.22331/q-2021-06-17-479)[[Tate et al. 2023a]](https://doi.org/10.22331/q-2023-09-26-1121).&quot;, &quot;Intent&quot;: &quot;How to utilize efficient approximations in quantum algorithms to improve the solution quality or speed up the computation?&quot;, &quot;Result&quot;: &quot;The quantum algorithm employed in the second step utilizes the approximation as a starting point to improve upon. Due to the biased initial state, optimal solutions can be explored quicker and the solution quality achievable in a set amount of time may therefore increase. Moreover, this way the workload of the overall computation can be distributed to multiple devices, e.g., classical and quantum devices.&quot;, &quot;Context&quot;: &quot;For many computationally hard problems, efficient approximation algorithms exist. However, typical quantum algorithms neglect these approximations and valuable information remains unused as the quantum algorithm starts from a neutral position. As a result, deep quantum circuits may be required, which increases accumulative error rates, and more quantum resources may be required to solve a problem.&quot;, &quot;Examples&quot;: &quot;&#8212;&quot;, &quot;Solution&quot;: &quot;Encode approximations into the initial state of quantum circuits, thereby biasing the initial quantum state towards viable solutions. Hence, a chain of algorithm executions as depicted in the solution sketch below is beneficial: First, an efficient algorithm is utilized to approximate a solution of a given problem instance. This can often be achieved at low cost on classical hardware. Then, the initial state $|\\psi\\rangle$ of the subsequent quantum algorithm is biased toward the approximation and the algorithm is executed on a quantum device to obtain an improved solution.\n\n![Solution Sketch Biased Initial State](https://raw.githubusercontent.com/PatternAtlas/pattern-atlas-content/2640a277baf681f3309e942c04a34de037d1629b/sketches/quantum_computing_patterns/biased-initial-state.svg)&quot;, &quot;Known Uses&quot;: &quot;Egger et al. introduce a biased initial state for [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337) and the Maximum Cut problem (MaxCut) utilizing the classical Goemans-Williamson approximation algorithm [[Egger et al. 2021]](https://doi.org/10.22331/q-2021-06-17-479). Similarly, Tate et al. adapt [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337) for MaxCut with a Burer-Monteiro relaxation of the problem [[Tate et al. 2023b]](https://doi.org/10.1145/3549554). [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337) was also adapted for a biased initial state for the Knapsack problem [[van Dam et al. 2021]](https://doi.org/10.1109/QCE52317.2021.00033). Wang proposes a \&quot;classically-boosted\&quot; quantum algorithm for the Maximum 3-Satisfiability and Maximum Bisection problems based on biased initial states [[Wang 2022]](https://arxiv.org/abs/2203.13936). Beisel et al. propose a workflow modeling construct facilitating the integration of warm-starts via biased initial states in [VQAs](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) [[Beisel et al. 2023]](https://www.doi.org/10.5220/0011997500003488).&quot;, &quot;Related Pattern&quot;: &quot;This pattern is a refinement of the [Warm-Start](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/3ea9e187-e91b-4852-84eb-b35b5c480892) pattern and related to the [State Preparation patterns](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/312bc9d3-26c0-40ae-b90b-56effd136c0d), e.g., [Angle Encoding](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/e595558d-bfea-4b82-9f47-a38a2097b245), since different encodings may be applied to prepare and bias the initial state of a quantum algorithm [[Weigold et al. 2021a]](https://doi.org/10.1007/978-3-030-87568-8_2) [[Weigold et al. 2021b]](https://doi.org/10.1109/ICSA-C52384.2021.00025). Moreover, it can be applied with the [VQA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) pattern and its refinements, such as the [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337) [[Weigold et al. 2021a]](https://doi.org/10.1007/978-3-030-87568-8_2).&quot;}"/>
            <column name="icon_url" value="https://raw.githubusercontent.com/PatternAtlas/pattern-atlas-content/2be447fbdd370cf59a73ac4389432ddcfe1b864e/icons/quantum_computing_patterns/warm-start-biased-initial-state-thin.svg"/>
            <column name="rendered_content" value="{&quot;Alias&quot;: &quot;&#8212;&quot;, &quot;Forces&quot;: &quot;Moreover, current quantum devices are error-prone, thus, the depth of executable quantum circuits is limited. However, including approximations requires special care, as it can limit the quantum algorithm in an unintended way [[Cain et al. 2022]](https://arxiv.org/abs/2207.05089)[[Truger et al. 2024]](https://arxiv.org/abs/2402.17378). Also, changing the initial state may require additional adaptations of corresponding parts of the quantum circuit [[Egger et al. 2021]](https://doi.org/10.22331/q-2021-06-17-479)[[Tate et al. 2023a]](https://doi.org/10.22331/q-2023-09-26-1121).&quot;, &quot;Intent&quot;: &quot;How to utilize efficient approximations in quantum algorithms to improve the solution quality or speed up the computation?&quot;, &quot;Result&quot;: &quot;The quantum algorithm employed in the second step utilizes the approximation as a starting point to improve upon. Due to the biased initial state, optimal solutions can be explored quicker and the solution quality achievable in a set amount of time may therefore increase. Moreover, this way the workload of the overall computation can be distributed to multiple devices, e.g., classical and quantum devices.&quot;, &quot;Context&quot;: &quot;For many computationally hard problems, efficient approximation algorithms exist. However, typical quantum algorithms neglect these approximations and valuable information remains unused as the quantum algorithm starts from a neutral position. As a result, deep quantum circuits may be required, which increases accumulative error rates, and more quantum resources may be required to solve a problem.&quot;, &quot;Examples&quot;: &quot;&#8212;&quot;, &quot;Solution&quot;: &quot;Encode approximations into the initial state of quantum circuits, thereby biasing the initial quantum state towards viable solutions. Hence, a chain of algorithm executions as depicted in the solution sketch below is beneficial: First, an efficient algorithm is utilized to approximate a solution of a given problem instance. This can often be achieved at low cost on classical hardware. Then, the initial state $|\\psi\\rangle$ of the subsequent quantum algorithm is biased toward the approximation and the algorithm is executed on a quantum device to obtain an improved solution.\n\n![Solution Sketch Biased Initial State](https://raw.githubusercontent.com/PatternAtlas/pattern-atlas-content/2640a277baf681f3309e942c04a34de037d1629b/sketches/quantum_computing_patterns/biased-initial-state.svg)&quot;, &quot;Known Uses&quot;: &quot;Egger et al. introduce a biased initial state for [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337) and the Maximum Cut problem (MaxCut) utilizing the classical Goemans-Williamson approximation algorithm [[Egger et al. 2021]](https://doi.org/10.22331/q-2021-06-17-479). Similarly, Tate et al. adapt [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337) for MaxCut with a Burer-Monteiro relaxation of the problem [[Tate et al. 2023b]](https://doi.org/10.1145/3549554). [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337) was also adapted for a biased initial state for the Knapsack problem [[van Dam et al. 2021]](https://doi.org/10.1109/QCE52317.2021.00033). Wang proposes a \&quot;classically-boosted\&quot; quantum algorithm for the Maximum 3-Satisfiability and Maximum Bisection problems based on biased initial states [[Wang 2022]](https://arxiv.org/abs/2203.13936). Beisel et al. propose a workflow modeling construct facilitating the integration of warm-starts via biased initial states in [VQAs](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) [[Beisel et al. 2023]](https://www.doi.org/10.5220/0011997500003488).&quot;, &quot;Related Pattern&quot;: &quot;This pattern is a refinement of the [Warm-Start](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/3ea9e187-e91b-4852-84eb-b35b5c480892) pattern and related to the [State Preparation patterns](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/312bc9d3-26c0-40ae-b90b-56effd136c0d), e.g., [Angle Encoding](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/e595558d-bfea-4b82-9f47-a38a2097b245), since different encodings may be applied to prepare and bias the initial state of a quantum algorithm [[Weigold et al. 2021a]](https://doi.org/10.1007/978-3-030-87568-8_2) [[Weigold et al. 2021b]](https://doi.org/10.1109/ICSA-C52384.2021.00025). Moreover, it can be applied with the [VQA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) pattern and its refinements, such as the [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337) [[Weigold et al. 2021a]](https://doi.org/10.1007/978-3-030-87568-8_2).&quot;}"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
            <column name="paper_ref" value="F. Truger et al.: Warm-Starting Patterns for Quantum Algorithms. The Sixteenth International Conference on Pervasive Patterns and Applications (PATTERNS), 2024 [in press]"/>
            <column name="deployment_modeling_behavior_pattern"/>
            <column name="deployment_modeling_structure_pattern"/>
            <column name="tags" value="augmentation"/>
        </insert>
        <insert tableName="pattern">
            <column name="id" value="8c893b97-5980-4c81-870a-1cb4917dc33f"/>
            <column name="name" value="Pre-Trained Feature Extractor"/>
            <column name="uri" value="https://patternpedia.org/patternLanguages/quantumAlgorithmPatterns/pre-trainedFeatureExtractor"/>
            <column name="content" value="{&quot;Alias&quot;: &quot;Quantum Transfer Learning&quot;, &quot;Forces&quot;: &quot;The width of circuits implementing QNNs is limited by the number of available qubits. In addition, quantum devices are scarce resources that should be utilized as efficiently as possible. However, naively reducing the original data items may result in the loss of information relevant for the computation. Large pre-trained classical models for various general tasks, such as object recognition for images, are widely available or can be created at low cost.&quot;, &quot;Intent&quot;: &quot;How to process large data items through quantum neural networks (QNNs) when the number of available qubits is lower than the size of a data item?&quot;, &quot;Result&quot;: &quot;Due to the compressed representation obtained from the pre-trained feature extractor, fewer qubits are required to process data in the QNN. Furthermore, the compressed nature of the data may reduce the QNN's training time, as irrelevant information has already been omitted from the training data.&quot;, &quot;Context&quot;: &quot;A QNN shall be trained for a specific task, that requires the processing of large data items, e.g., images or multi-dimensional data. However, the number of qubits required to load such data items into the QNN is larger than the number of qubits of the available quantum devices.&quot;, &quot;Examples&quot;: &quot;&#8212;&quot;, &quot;Solution&quot;: &quot;Use a pre-trained classical model to reduce the dimensions of the data items and train the QNN based on the reduced data. As shown in the solution sketch below, a pre-trained classical model for a wide range purpose, such as a neural network trained for object recognition, can be utilized for a hybrid QNN to be trained for a related special purpose task. Intermediate values of inputs processed through such models, e.g., those present at a condensed next-to-last neural network layer, can be seen as a compressed representation of the original data exhibiting its most significant features. Thus, the pre-trained model serves as a feature extractor. These features can be encoded into a quantum state to train the QNN for the target task.\n\n![Solution Sketch Pre-Trained Feature Extractor](https://raw.githubusercontent.com/PatternAtlas/pattern-atlas-content/2640a277baf681f3309e942c04a34de037d1629b/sketches/quantum_computing_patterns/pre-trained-feature-extractor.svg)&quot;, &quot;Known Uses&quot;: &quot;Pre-Trained Feature Extractor is frequently used when image processing, particularly image classification, shall be enhanced with QNNs [[Mari et al. 2020]](https://doi.org/10.22331/q-2020-10-09-340) [[Mittal and Dana 2020]](https://doi.org/10.1109/SCES50439.2020.9236711) [[Gokhale et al. 2020]](https://doi.org/10.1142/S0219749920500240) [[Azevedo et al. 2022]](https://doi.org/10.1007/s42484-022-00062-4) [[Umer et al. 2022]](https://doi.org/10.1002/cpe.6434) [[Kanimozhi et al. 2022]](https://doi.org/10.1109/ICITIIT54346.2022.9744220) [[Furutanpey et al. 2023]](https://doi.org/10.1109/QSW59989.2023.00021). It was also applied for text classification [[Yang et al. 2022]](https://doi.org/10.1109/ICASSP43922.2022.9746412). Moreover, autoencoders [[Kramer 1991]](https://doi.org/10.1002/aic.690370209) can be considered a special case of Pre-Trained Feature Extractor, that are designed and trained specifically for the purpose of data compression.&quot;, &quot;Related Pattern&quot;: &quot;This pattern refines the [Warm-Start](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/3ea9e187-e91b-4852-84eb-b35b5c480892)  pattern and is related to the [State Preparation patterns](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/312bc9d3-26c0-40ae-b90b-56effd136c0d), e.g., [Angle Encoding](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/e595558d-bfea-4b82-9f47-a38a2097b245), [[Weigold et al. 2021a]](https://doi.org/10.1007/978-3-030-87568-8_2) [[Weigold et al. 2021b]](https://doi.org/10.1109/ICSA-C52384.2021.00025). Different encodings may be applied to encode the extracted features into a quantum state. It is typically applied in conjunction with QNNs, a form of [VQA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) [[Cerezo et al. 2021]](https://doi.org/10.1038/s42254-021-00348-9). Furthermore, the [Circuit Cutting](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/3d9bca6e-5fca-40c5-b005-8a794958f3aa) pattern solves a similar problem by partitioning the computation of a large quantum circuit into computations of multiple smaller circuits [[Bechtold et al. 2023]](https://hillside.net/conferences/plop-conference-proceedings).&quot;}"/>
            <column name="icon_url" value="https://raw.githubusercontent.com/PatternAtlas/pattern-atlas-content/2be447fbdd370cf59a73ac4389432ddcfe1b864e/icons/quantum_computing_patterns/warm-start-pre-trained-feature-extractor-thin.svg"/>
            <column name="rendered_content" value="{&quot;Alias&quot;: &quot;Quantum Transfer Learning&quot;, &quot;Forces&quot;: &quot;The width of circuits implementing QNNs is limited by the number of available qubits. In addition, quantum devices are scarce resources that should be utilized as efficiently as possible. However, naively reducing the original data items may result in the loss of information relevant for the computation. Large pre-trained classical models for various general tasks, such as object recognition for images, are widely available or can be created at low cost.&quot;, &quot;Intent&quot;: &quot;How to process large data items through quantum neural networks (QNNs) when the number of available qubits is lower than the size of a data item?&quot;, &quot;Result&quot;: &quot;Due to the compressed representation obtained from the pre-trained feature extractor, fewer qubits are required to process data in the QNN. Furthermore, the compressed nature of the data may reduce the QNN's training time, as irrelevant information has already been omitted from the training data.&quot;, &quot;Context&quot;: &quot;A QNN shall be trained for a specific task, that requires the processing of large data items, e.g., images or multi-dimensional data. However, the number of qubits required to load such data items into the QNN is larger than the number of qubits of the available quantum devices.&quot;, &quot;Examples&quot;: &quot;&#8212;&quot;, &quot;Solution&quot;: &quot;Use a pre-trained classical model to reduce the dimensions of the data items and train the QNN based on the reduced data. As shown in the solution sketch below, a pre-trained classical model for a wide range purpose, such as a neural network trained for object recognition, can be utilized for a hybrid QNN to be trained for a related special purpose task. Intermediate values of inputs processed through such models, e.g., those present at a condensed next-to-last neural network layer, can be seen as a compressed representation of the original data exhibiting its most significant features. Thus, the pre-trained model serves as a feature extractor. These features can be encoded into a quantum state to train the QNN for the target task.\n\n![Solution Sketch Pre-Trained Feature Extractor](https://raw.githubusercontent.com/PatternAtlas/pattern-atlas-content/2640a277baf681f3309e942c04a34de037d1629b/sketches/quantum_computing_patterns/pre-trained-feature-extractor.svg)&quot;, &quot;Known Uses&quot;: &quot;Pre-Trained Feature Extractor is frequently used when image processing, particularly image classification, shall be enhanced with QNNs [[Mari et al. 2020]](https://doi.org/10.22331/q-2020-10-09-340) [[Mittal and Dana 2020]](https://doi.org/10.1109/SCES50439.2020.9236711) [[Gokhale et al. 2020]](https://doi.org/10.1142/S0219749920500240) [[Azevedo et al. 2022]](https://doi.org/10.1007/s42484-022-00062-4) [[Umer et al. 2022]](https://doi.org/10.1002/cpe.6434) [[Kanimozhi et al. 2022]](https://doi.org/10.1109/ICITIIT54346.2022.9744220) [[Furutanpey et al. 2023]](https://doi.org/10.1109/QSW59989.2023.00021). It was also applied for text classification [[Yang et al. 2022]](https://doi.org/10.1109/ICASSP43922.2022.9746412). Moreover, autoencoders [[Kramer 1991]](https://doi.org/10.1002/aic.690370209) can be considered a special case of Pre-Trained Feature Extractor, that are designed and trained specifically for the purpose of data compression.&quot;, &quot;Related Pattern&quot;: &quot;This pattern refines the [Warm-Start](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/3ea9e187-e91b-4852-84eb-b35b5c480892)  pattern and is related to the [State Preparation patterns](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/312bc9d3-26c0-40ae-b90b-56effd136c0d), e.g., [Angle Encoding](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/e595558d-bfea-4b82-9f47-a38a2097b245), [[Weigold et al. 2021a]](https://doi.org/10.1007/978-3-030-87568-8_2) [[Weigold et al. 2021b]](https://doi.org/10.1109/ICSA-C52384.2021.00025). Different encodings may be applied to encode the extracted features into a quantum state. It is typically applied in conjunction with QNNs, a form of [VQA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) [[Cerezo et al. 2021]](https://doi.org/10.1038/s42254-021-00348-9). Furthermore, the [Circuit Cutting](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/3d9bca6e-5fca-40c5-b005-8a794958f3aa) pattern solves a similar problem by partitioning the computation of a large quantum circuit into computations of multiple smaller circuits [[Bechtold et al. 2023]](https://hillside.net/conferences/plop-conference-proceedings).&quot;}"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
            <column name="paper_ref" value="F. Truger et al.: Warm-Starting Patterns for Quantum Algorithms. The Sixteenth International Conference on Pervasive Patterns and Applications (PATTERNS), 2024 [in press]"/>
            <column name="deployment_modeling_behavior_pattern"/>
            <column name="deployment_modeling_structure_pattern"/>
            <column name="tags" value="augmentation"/>
        </insert>
        <insert tableName="pattern">
            <column name="id" value="f417a855-4d52-4a30-b88a-e34a7eaebe86"/>
            <column name="name" value="Variational Parameter Transfer"/>
            <column name="uri" value="https://patternpedia.org/patternLanguages/quantumAlgorithmPatterns/variationalParameterTransfer"/>
            <column name="content" value="{&quot;Alias&quot;: &quot;&#8212;&quot;, &quot;Forces&quot;: &quot;Obtaining viable parameter initializations for [VQAs](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) is challenging due to large parameter spaces and effects, such as barren plateaus [[Cerezo et al. 2021]](https://doi.org/10.1038/s41467-021-21728-w) and non-convex optimization landscapes [[Huembeli and Dauphin 2021]](https://doi.org/10.1088/2058-9565/abdbc9). Barren plateaus are areas with vanishing gradients in a cost function's parameter space that must be avoided, whereas local minima in non-convex optimization landscapes pose an additional challenge to efficient parameter initialization as they disturb the search for a global optimum.&quot;, &quot;Intent&quot;: &quot;How to obtain a problem-aware parameter initialization for [Variational Quantum Algorithms](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) (VQAs) that reduces the optimization runtime?&quot;, &quot;Result&quot;: &quot;Parameter transfers can reduce the number of iterations of the optimization loop. A favorable parameter initialization can also increase the likelihood of finding globally optimal parameter values and thus increase the solution quality.&quot;, &quot;Context&quot;: &quot;A VQA needs to be executed on a quantum device, which encompasses the optimization of its variational parameters. Parameter optimization requires repeated access to the quantum device, typically starting with random initial parameter values [[Kulshrestha and Safro 2022]](https://doi.org/10.1109/QCE53715.2022.00039), to sample solutions and determine a direction for their optimization, e.g., through gradient descent.&quot;, &quot;Examples&quot;: &quot;&#8212;&quot;, &quot;Solution&quot;: &quot;Transfer viable variational parameter values from related problem instances. As shown in the solution sketch below, optimized parameter values may be stored or directly reused for new problem instances. In many cases, it can be expected that optimized parameter values for a solved problem instance are in proximity of viable parameter values for a related or similar new problem instance. Therefore, optimized parameter values from earlier executions may be utilized for a problem-aware parameter initialization instead of a random initialization. Appropriate databases, toolkits, and provenance systems for quantum computing [[Shaydulin et al. 2021]](https://doi.org/10.1109/QCS54837.2021.00011) [[Weder et al. 2021]](https://doi.org/10.1049/qtc2.12012) facilitate the optional storage of optimized parameter values for their utilization in later executions.\n\n![Solution Sketch Variational Parameter Transfer](https://raw.githubusercontent.com/PatternAtlas/pattern-atlas-content/2640a277baf681f3309e942c04a34de037d1629b/sketches/quantum_computing_patterns/variational-parameter-transfer.svg)&quot;, &quot;Known Uses&quot;: &quot;Variational Parameter Transfer has been frequently proposed and applied for [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337) and MaxCut [[Brandao et al. 2018]](https://arxiv.org/abs/1812.04170) [[Wurtz and Lykov 2021]](https://doi.org/10.1103/PhysRevA.104.052419) [[Galda et al. 2021]](https://doi.org/10.1109/QCE52317.2021.00034) [[Shaydulin et al. 2023]](https://doi.org/10.1145/3584706). Moreover, Shaydulin et al.'s repository of preoptimized parameters implements the storage option [[Shaydulin et al. 2021]](https://doi.org/10.1109/QCS54837.2021.00011). Beisel et al. propose a modeling construct for workflows to integrate warm-starts via parameter initialization in [VQAs](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) [[Beisel et al. 2023]](https://www.doi.org/10.5220/0011997500003488).&quot;, &quot;Related Pattern&quot;: &quot;This pattern is a refinement of the [Warm-Start](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/3ea9e187-e91b-4852-84eb-b35b5c480892) pattern and can be applied in conjunction with  [VQA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7), including its refinements like [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337), [[Weigold et al. 2021a]](https://doi.org/10.1007/978-3-030-87568-8_2).&quot;}"/>
            <column name="icon_url" value="https://raw.githubusercontent.com/PatternAtlas/pattern-atlas-content/2be447fbdd370cf59a73ac4389432ddcfe1b864e/icons/quantum_computing_patterns/warm-start-variational-parameter-transfer-thin.svg"/>
            <column name="rendered_content" value="{&quot;Alias&quot;: &quot;&#8212;&quot;, &quot;Forces&quot;: &quot;Obtaining viable parameter initializations for [VQAs](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) is challenging due to large parameter spaces and effects, such as barren plateaus [[Cerezo et al. 2021]](https://doi.org/10.1038/s41467-021-21728-w) and non-convex optimization landscapes [[Huembeli and Dauphin 2021]](https://doi.org/10.1088/2058-9565/abdbc9). Barren plateaus are areas with vanishing gradients in a cost function's parameter space that must be avoided, whereas local minima in non-convex optimization landscapes pose an additional challenge to efficient parameter initialization as they disturb the search for a global optimum.&quot;, &quot;Intent&quot;: &quot;How to obtain a problem-aware parameter initialization for [Variational Quantum Algorithms](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) (VQAs) that reduces the optimization runtime?&quot;, &quot;Result&quot;: &quot;Parameter transfers can reduce the number of iterations of the optimization loop. A favorable parameter initialization can also increase the likelihood of finding globally optimal parameter values and thus increase the solution quality.&quot;, &quot;Context&quot;: &quot;A VQA needs to be executed on a quantum device, which encompasses the optimization of its variational parameters. Parameter optimization requires repeated access to the quantum device, typically starting with random initial parameter values [[Kulshrestha and Safro 2022]](https://doi.org/10.1109/QCE53715.2022.00039), to sample solutions and determine a direction for their optimization, e.g., through gradient descent.&quot;, &quot;Examples&quot;: &quot;&#8212;&quot;, &quot;Solution&quot;: &quot;Transfer viable variational parameter values from related problem instances. As shown in the solution sketch below, optimized parameter values may be stored or directly reused for new problem instances. In many cases, it can be expected that optimized parameter values for a solved problem instance are in proximity of viable parameter values for a related or similar new problem instance. Therefore, optimized parameter values from earlier executions may be utilized for a problem-aware parameter initialization instead of a random initialization. Appropriate databases, toolkits, and provenance systems for quantum computing [[Shaydulin et al. 2021]](https://doi.org/10.1109/QCS54837.2021.00011) [[Weder et al. 2021]](https://doi.org/10.1049/qtc2.12012) facilitate the optional storage of optimized parameter values for their utilization in later executions.\n\n![Solution Sketch Variational Parameter Transfer](https://raw.githubusercontent.com/PatternAtlas/pattern-atlas-content/2640a277baf681f3309e942c04a34de037d1629b/sketches/quantum_computing_patterns/variational-parameter-transfer.svg)&quot;, &quot;Known Uses&quot;: &quot;Variational Parameter Transfer has been frequently proposed and applied for [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337) and MaxCut [[Brandao et al. 2018]](https://arxiv.org/abs/1812.04170) [[Wurtz and Lykov 2021]](https://doi.org/10.1103/PhysRevA.104.052419) [[Galda et al. 2021]](https://doi.org/10.1109/QCE52317.2021.00034) [[Shaydulin et al. 2023]](https://doi.org/10.1145/3584706). Moreover, Shaydulin et al.'s repository of preoptimized parameters implements the storage option [[Shaydulin et al. 2021]](https://doi.org/10.1109/QCS54837.2021.00011). Beisel et al. propose a modeling construct for workflows to integrate warm-starts via parameter initialization in [VQAs](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) [[Beisel et al. 2023]](https://www.doi.org/10.5220/0011997500003488).&quot;, &quot;Related Pattern&quot;: &quot;This pattern is a refinement of the [Warm-Start](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/3ea9e187-e91b-4852-84eb-b35b5c480892) pattern and can be applied in conjunction with  [VQA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7), including its refinements like [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337), [[Weigold et al. 2021a]](https://doi.org/10.1007/978-3-030-87568-8_2).&quot;}"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
            <column name="paper_ref" value="F. Truger et al.: Warm-Starting Patterns for Quantum Algorithms. The Sixteenth International Conference on Pervasive Patterns and Applications (PATTERNS), 2024 [in press]"/>
            <column name="deployment_modeling_behavior_pattern"/>
            <column name="deployment_modeling_structure_pattern"/>
            <column name="tags" value="augmentation"/>
        </insert>
        <insert tableName="pattern">
            <column name="id" value="b92daa20-265c-4276-b138-3aa5a7bbc37f"/>
            <column name="name" value="Chained Optimization"/>
            <column name="uri" value="https://patternpedia.org/patternLanguages/quantumAlgorithmPatterns/chainedOptimization"/>
            <column name="content" value="{&quot;Alias&quot;: &quot;&#8212;&quot;, &quot;Forces&quot;: &quot;Local minima in non-convex optimization landscapes and barren plateaus hinder the optimization, as the optimizer may be unable to reach a global optimum. Moreover, evaluating all possible parameter values is infeasibly expensive.&quot;, &quot;Intent&quot;: &quot;How to avoid local optima and improve convergence when optimizing variational parameter values for [Variational Quantum Algorithms](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) (VQAs)?&quot;, &quot;Result&quot;: &quot;By chaining optimizers, the subsequent optimizers utilize previously obtained results as starting points to improve upon. Thereby, optimizers are combined to benefit from their respective strengths and achieve cost-efficient optimization.&quot;, &quot;Context&quot;: &quot;Optimal variational parameter values for a [VQA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) need to be determined. The performance of the algorithm depends heavily on these values and a global optimum in the parameter space is needed to obtain optimal solutions.&quot;, &quot;Examples&quot;: &quot;&#8212;&quot;, &quot;Solution&quot;: &quot;Chain different optimizers with different scopes or strengths together. As indicated in the solution sketch below, a global optimization strategy can be combined with a subsequent local optimizer. The former would determine a general area of interest in the overall optimization landscape. Afterward, the local optimizer is started from a point in this area of interest and searches on a smaller scale, aiming to find the global optimum.\n\n![Solution Sketch Chained Optimization](https://raw.githubusercontent.com/PatternAtlas/pattern-atlas-content/2640a277baf681f3309e942c04a34de037d1629b/sketches/quantum_computing_patterns/chained-optimization.svg)&quot;, &quot;Known Uses&quot;: &quot;[[Rad et al. 2022]](https://arxiv.org/abs/2203.02464) use this method to avoid barren plateaus in [VQAs](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7). Tao et al. apply it in a QNN optimization [[Tao et al. 2023]](https://doi.org/10.1109/QSW59989.2023.00019). Wauters et al. supplement their Reinforcement Learning-based optimization approach for [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337) with subsequent gradient-based local optimization [[Wauters et al. 2020]](https://doi.org/10.1103/PhysRevResearch.2.033446) .&quot;, &quot;Related Pattern&quot;: &quot;This pattern refines the [Warm-Start](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/3ea9e187-e91b-4852-84eb-b35b5c480892) pattern and can be applied in conjunction with [VQA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7), including [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337), [[Weigold et al. 2021a]](https://doi.org/10.1007/978-3-030-87568-8_2). It is similar to the [Variational Parameter Transfer](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/f417a855-4d52-4a30-b88a-e34a7eaebe86) pattern, with an unaltered problem instance, while the algorithm in use, specifically the optimization algorithm, is exchanged instead.&quot;}"/>
            <column name="icon_url" value="https://raw.githubusercontent.com/PatternAtlas/pattern-atlas-content/2be447fbdd370cf59a73ac4389432ddcfe1b864e/icons/quantum_computing_patterns/warm-start-chained-optimization-thin.svg"/>
            <column name="rendered_content" value="{&quot;Alias&quot;: &quot;&#8212;&quot;, &quot;Forces&quot;: &quot;Local minima in non-convex optimization landscapes and barren plateaus hinder the optimization, as the optimizer may be unable to reach a global optimum. Moreover, evaluating all possible parameter values is infeasibly expensive.&quot;, &quot;Intent&quot;: &quot;How to avoid local optima and improve convergence when optimizing variational parameter values for [Variational Quantum Algorithms](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) (VQAs)?&quot;, &quot;Result&quot;: &quot;By chaining optimizers, the subsequent optimizers utilize previously obtained results as starting points to improve upon. Thereby, optimizers are combined to benefit from their respective strengths and achieve cost-efficient optimization.&quot;, &quot;Context&quot;: &quot;Optimal variational parameter values for a [VQA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7) need to be determined. The performance of the algorithm depends heavily on these values and a global optimum in the parameter space is needed to obtain optimal solutions.&quot;, &quot;Examples&quot;: &quot;&#8212;&quot;, &quot;Solution&quot;: &quot;Chain different optimizers with different scopes or strengths together. As indicated in the solution sketch below, a global optimization strategy can be combined with a subsequent local optimizer. The former would determine a general area of interest in the overall optimization landscape. Afterward, the local optimizer is started from a point in this area of interest and searches on a smaller scale, aiming to find the global optimum.\n\n![Solution Sketch Chained Optimization](https://raw.githubusercontent.com/PatternAtlas/pattern-atlas-content/2640a277baf681f3309e942c04a34de037d1629b/sketches/quantum_computing_patterns/chained-optimization.svg)&quot;, &quot;Known Uses&quot;: &quot;[[Rad et al. 2022]](https://arxiv.org/abs/2203.02464) use this method to avoid barren plateaus in [VQAs](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7). Tao et al. apply it in a QNN optimization [[Tao et al. 2023]](https://doi.org/10.1109/QSW59989.2023.00019). Wauters et al. supplement their Reinforcement Learning-based optimization approach for [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337) with subsequent gradient-based local optimization [[Wauters et al. 2020]](https://doi.org/10.1103/PhysRevResearch.2.033446) .&quot;, &quot;Related Pattern&quot;: &quot;This pattern refines the [Warm-Start](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/3ea9e187-e91b-4852-84eb-b35b5c480892) pattern and can be applied in conjunction with [VQA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/bc795a9b-7977-4e01-b513-f9f5aba38aa7), including [QAOA](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/da93f915-7f4c-49df-99d0-80d91f26a337), [[Weigold et al. 2021a]](https://doi.org/10.1007/978-3-030-87568-8_2). It is similar to the [Variational Parameter Transfer](pattern-languages/af7780d5-1f97-4536-8da7-4194b093ab1d/f417a855-4d52-4a30-b88a-e34a7eaebe86) pattern, with an unaltered problem instance, while the algorithm in use, specifically the optimization algorithm, is exchanged instead.&quot;}"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
            <column name="paper_ref" value="F. Truger et al.: Warm-Starting Patterns for Quantum Algorithms. The Sixteenth International Conference on Pervasive Patterns and Applications (PATTERNS), 2024 [in press]"/>
            <column name="deployment_modeling_behavior_pattern"/>
            <column name="deployment_modeling_structure_pattern"/>
            <column name="tags" value="augmentation"/>
        </insert>
        <insert tableName="undirected_edge">
            <column name="id" value="25db1f21-831d-4715-ba52-a69c7c114288"/>
            <column name="description" value="null"/>
            <column name="type" value="isRelatedTo"/>
            <column name="p1_id" value="312bc9d3-26c0-40ae-b90b-56effd136c0d"/>
            <column name="p2_id" value="d3f6b18a-c8c1-4010-b750-b71d95eb5f5e"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
        </insert>
        <insert tableName="undirected_edge">
            <column name="id" value="3dfd5e22-2a86-4793-a2d7-1e415803feb2"/>
            <column name="description" value="null"/>
            <column name="type" value="canBeUsedWith"/>
            <column name="p1_id" value="bc795a9b-7977-4e01-b513-f9f5aba38aa7"/>
            <column name="p2_id" value="d3f6b18a-c8c1-4010-b750-b71d95eb5f5e"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
        </insert>
        <insert tableName="undirected_edge">
            <column name="id" value="10968981-4a12-4df1-b121-c0549fd1a951"/>
            <column name="description" value="null"/>
            <column name="type" value="isRelatedTo"/>
            <column name="p1_id" value="312bc9d3-26c0-40ae-b90b-56effd136c0d"/>
            <column name="p2_id" value="8c893b97-5980-4c81-870a-1cb4917dc33f"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
        </insert>
        <insert tableName="undirected_edge">
            <column name="id" value="18d7b02a-5c91-4f73-80cf-c21fad10d221"/>
            <column name="description" value="null"/>
            <column name="type" value="canBeUsedWith"/>
            <column name="p1_id" value="bc795a9b-7977-4e01-b513-f9f5aba38aa7"/>
            <column name="p2_id" value="8c893b97-5980-4c81-870a-1cb4917dc33f"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
        </insert>
        <insert tableName="undirected_edge">
            <column name="id" value="41bb4ccb-9f61-4b38-8b7c-0b848e9909c3"/>
            <column name="description" value="null"/>
            <column name="type" value="isAlternativeTo"/>
            <column name="p1_id" value="3d9bca6e-5fca-40c5-b005-8a794958f3aa"/>
            <column name="p2_id" value="8c893b97-5980-4c81-870a-1cb4917dc33f"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
        </insert>
        <insert tableName="undirected_edge">
            <column name="id" value="6860f865-a976-4beb-8a83-6dc821eb2921"/>
            <column name="description" value="null"/>
            <column name="type" value="canBeUsedWith"/>
            <column name="p1_id" value="bc795a9b-7977-4e01-b513-f9f5aba38aa7"/>
            <column name="p2_id" value="f417a855-4d52-4a30-b88a-e34a7eaebe86"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
        </insert>
        <insert tableName="undirected_edge">
            <column name="id" value="b0a49f92-cd36-4405-8c95-b5a38a8d3e58"/>
            <column name="description" value="null"/>
            <column name="type" value="canBeUsedWith"/>
            <column name="p1_id" value="bc795a9b-7977-4e01-b513-f9f5aba38aa7"/>
            <column name="p2_id" value="b92daa20-265c-4276-b138-3aa5a7bbc37f"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
        </insert>
        <insert tableName="undirected_edge">
            <column name="id" value="142631fe-0b04-44ac-9dfa-14481663c65e"/>
            <column name="description" value="null"/>
            <column name="type" value="isVariationOf"/>
            <column name="p1_id" value="f417a855-4d52-4a30-b88a-e34a7eaebe86"/>
            <column name="p2_id" value="b92daa20-265c-4276-b138-3aa5a7bbc37f"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
        </insert>
        <insert tableName="directed_edge">
            <column name="id" value="6020d4e0-dbac-4cdd-a8f9-012a98cc79cd"/>
            <column name="description" value="null"/>
            <column name="type" value="refines"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
            <column name="source_id" value="d3f6b18a-c8c1-4010-b750-b71d95eb5f5e"/>
            <column name="target_id" value="3ea9e187-e91b-4852-84eb-b35b5c480892"/>
        </insert>
        <insert tableName="directed_edge">
            <column name="id" value="ffd80b50-7d12-441f-bd87-73c879aa4554"/>
            <column name="description" value="null"/>
            <column name="type" value="refines"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
            <column name="source_id" value="8c893b97-5980-4c81-870a-1cb4917dc33f"/>
            <column name="target_id" value="3ea9e187-e91b-4852-84eb-b35b5c480892"/>
        </insert>
        <insert tableName="directed_edge">
            <column name="id" value="9485c366-ee91-4a49-a93c-fd1686690b17"/>
            <column name="description" value="null"/>
            <column name="type" value="refines"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
            <column name="source_id" value="f417a855-4d52-4a30-b88a-e34a7eaebe86"/>
            <column name="target_id" value="3ea9e187-e91b-4852-84eb-b35b5c480892"/>
        </insert>
        <insert tableName="directed_edge">
            <column name="id" value="fe15bc94-f9fb-4d1d-8091-17b2de14db9b"/>
            <column name="description" value="null"/>
            <column name="type" value="refines"/>
            <column name="pattern_language_id" value="af7780d5-1f97-4536-8da7-4194b093ab1d"/>
            <column name="source_id" value="b92daa20-265c-4276-b138-3aa5a7bbc37f"/>
            <column name="target_id" value="3ea9e187-e91b-4852-84eb-b35b5c480892"/>
        </insert>
    </changeSet>
</databaseChangeLog>